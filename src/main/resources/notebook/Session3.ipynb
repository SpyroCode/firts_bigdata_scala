{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Session3.ipynb","provenance":[{"file_id":"1R9AXv1oPILNZwJZ7MZeASojVFNxlEAy5","timestamp":1592343736039}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"cfppRm94uGVo","colab_type":"code","colab":{}},"source":["!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q http://apache.osuosl.org/spark/spark-2.4.6/spark-2.4.6-bin-hadoop2.7.tgz\n","!tar xf spark-2.4.6-bin-hadoop2.7.tgz\n","!pip install -q findspark"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bTJxmZ4suG6b","colab_type":"code","colab":{}},"source":["ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FhAzN9WOuIA3","colab_type":"code","colab":{}},"source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.6-bin-hadoop2.7\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lfe_VzlhuP1x","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595202314548,"user_tz":300,"elapsed":965,"user":{"displayName":"manuel osorio","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYn-jJamadL9N1xU9mWU1MrQjHrUBVR92ABfe5=s64","userId":"11075609001122154855"}}},"source":["import time\n","import findspark\n","findspark.init()\n","\n","from pyspark.sql import SparkSession\n","from pyspark import SparkContext, SparkConf\n","from pyspark.sql import SQLContext\n","\n","conf = SparkConf().setAppName('APP_NAME')\n","conf = conf.setMaster(\"local[*]\").set('spark.submit.deployMode', 'client')\n","sc = SparkContext(conf=conf)\n","\n","spark = SparkSession(sc)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LwDDSK2TY9Wh","colab_type":"text"},"source":["#Spark SQL"]},{"cell_type":"code","metadata":{"id":"d5Tlr9vi3b7i","colab_type":"code","colab":{}},"source":["df = spark.read.option(\"header\",\"true\")\\\n","               .option(\"inferschema\",\"false\")\\\n","               .option(\"sep\",\",\")\\\n","               .csv(\"datasets_covid_jpn_total.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DAv1WsR_c7uQ","colab_type":"code","colab":{}},"source":["from pyspark.sql.functions import *\n","df1 = df.groupBy(col(\"Location\")).agg({\"positive\":\"count\"}).collect()\n","df1[:1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eCzW_Ryc4gt5","colab_type":"code","colab":{}},"source":["df.orderBy(col(\"Date\").asc()).show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SRqS7yvT_ftk","colab_type":"code","colab":{}},"source":["from pyspark.sql import Window\n","\n","w = (Window.partitionBy('Date').orderBy('Date'))\n","df2 = df.select(row_number().over(w).alias(\"orden\"), col(\"Date\"), col(\"Location\"))\n","df2.withColumn(\"indicador\", when(col(\"orden\") == 1, \"True\").when(col(\"orden\") == 2, \"False\").otherwise(\"Null\")).show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JRQNRhkPC1My","colab_type":"code","colab":{}},"source":["def functionFirst(df):\n","  w = (Window.partitionBy('Date').orderBy('Date'))\n","  df2 = df.select(row_number().over(w).alias(\"orden\"), col(\"Date\"), col(\"Location\"))\n","  df2.withColumn(\"indicador\", when(col(\"orden\") == 1, \"True\").when(col(\"orden\") == 2, \"False\").otherwise(\"Null\"))\n","\n","  return df2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iYkBJ_x3EKSz","colab_type":"code","colab":{}},"source":["df3 = functionFirst(df)\n","df3.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T8uKVvW-ETyh","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","\n","#Transformamos la data en listas que puedan ser tomadas dentro del plot\n","location = df.select(col(\"Location\")).toPandas().values.flatten().tolist()\n","positive = df.select(col(\"Positive\")).toPandas().values.flatten().tolist()\n","\n","#identificamos la longitud de objetos que entraran en el plot\n","y_pos = np.arange(len(location))\n","\n","#llenamos la funcion\n","plt.bar(y_pos, positive, align='center')\n","plt.xticks(y_pos, location)\n","plt.ylabel('Location')\n","plt.title('Curva de Contagio')\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HAk9aKVELUMA","colab_type":"code","colab":{}},"source":["#Procesamiento paralelo por map & reduce\n","from operator import add\n","\n","lines = spark.read.text(\"archivo1.txt\").rdd.map(lambda r: r[0])\n","counts = lines.flatMap(lambda x: x.split(' ')) \\\n","              .map(lambda x: (x, 1)) \\\n","              .reduceByKey(add)\n","\n","output = counts.collect()\n","for (word, count) in output:\n","    print(\"%s: %i\" % (word, count))\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MyBMDiVnPx-2","colab_type":"code","colab":{}},"source":["df = spark.read.option(\"header\",\"true\")\\\n","               .option(\"inferschema\",\"true\")\\\n","               .option(\"sep\",\",\")\\\n","               .csv(\"Caso1 - Dataset enfermedad corazon.csv\")\n","\n","df.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dRx0Tr5cQBzD","colab_type":"code","colab":{}},"source":["!pip install scorecardpy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L0grq4x8LW7M","colab_type":"code","colab":{}},"source":["\n","import scorecardpy as sc\n","import pandas as pd\n","type(df)\n","dfPandas = df.toPandas()\n","dt_s = sc.var_filter(dfPandas, y=\"Flag_hipertension\")\n","bins = sc.woebin(dt_s, y=\"Flag_hipertension\")\n","bins"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tsnHCn4AQaIp","colab_type":"code","colab":{}},"source":["sc.woebin_plot(bins)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bgrqUa7nY4NP","colab_type":"text"},"source":["#Spark Streaming"]},{"cell_type":"code","metadata":{"id":"mAvS3D-oRI4Z","colab_type":"code","colab":{}},"source":["from pyspark.streaming import StreamingContext\n","from pyspark.sql import Row\n","\n","ssc = StreamingContext(sc, 1)\n","\n","rddQueue = []\n","for i in range(5):\n","  rddQueue += [ssc.sparkContext.parallelize([j for j in range(1, 1001)], 10)]\n","\n","inputStream = ssc.queueStream(rddQueue)\n","mappedStream = inputStream.map(lambda x: (x % 10, 1))\n","reducedStream = mappedStream.reduceByKey(lambda a, b: a + b)\n","reducedStream.pprint()\n","\n","ssc.start()\n","time.sleep(6)\n","ssc.stop(stopSparkContext=True, stopGraceFully=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lNjXIkwhc5YY","colab_type":"text"},"source":["#MLib"]},{"cell_type":"code","metadata":{"id":"bLcnGcZ3aGDE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595202322290,"user_tz":300,"elapsed":945,"user":{"displayName":"manuel osorio","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYn-jJamadL9N1xU9mWU1MrQjHrUBVR92ABfe5=s64","userId":"11075609001122154855"}}},"source":["from pyspark.mllib.regression import LabeledPoint\n","from pyspark.mllib.stat import Statistics\n","from pyspark.mllib.util import MLUtils"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ta2m_BHxdWkX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":302},"executionInfo":{"status":"ok","timestamp":1595202336624,"user_tz":300,"elapsed":13509,"user":{"displayName":"manuel osorio","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYn-jJamadL9N1xU9mWU1MrQjHrUBVR92ABfe5=s64","userId":"11075609001122154855"}},"outputId":"dd4477cd-3793-457c-8fce-e0dd6fa701e5"},"source":["    filepath = 'sample_linear_regression_data.txt'\n","    corrType = 'pearson'\n","    \n","    points = MLUtils.loadLibSVMFile(sc, filepath)\\\n","        .map(lambda lp: LabeledPoint(lp.label, lp.features.toArray()))\n","\n","    print()\n","    print('Summary of data file: ' + filepath)\n","    print('%d data points' % points.count())\n","\n","    # Statistics (correlations)\n","    print()\n","    print('Correlation (%s) between label and each feature' % corrType)\n","    print('Feature\\tCorrelation')\n","    numFeatures = points.take(1)[0].features.size\n","    labelRDD = points.map(lambda lp: lp.label)\n","    for i in range(numFeatures):\n","        featureRDD = points.map(lambda lp: lp.features[i])\n","        corr = Statistics.corr(labelRDD, featureRDD, corrType)\n","        print('%d\\t%g' % (i, corr))\n","    print()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["\n","Summary of data file: sample_linear_regression_data.txt\n","501 data points\n","\n","Correlation (pearson) between label and each feature\n","Feature\tCorrelation\n","0\t0.00595645\n","1\t0.0332056\n","2\t-0.0406646\n","3\t0.123178\n","4\t0.0240118\n","5\t0.0648617\n","6\t-0.0223995\n","7\t-0.0279813\n","8\t-0.0359889\n","9\t0.0345207\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XpGCMoM4dY_S","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}